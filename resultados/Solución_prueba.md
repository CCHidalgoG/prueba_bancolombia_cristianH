# SoluciÃ³n prueba tÃ©cnica

por: Cristian Hidalgo

En el presente documento se explica la resoluciÃ³n de la prueba solicitada por Bancolombia. Se abordÃ³ el problema de segmentaciÃ³n de clientes para la prevenciÃ³n de lavado de activos y financiamiento del terrorismo. Se presentarÃ¡ el proceso seguido para resolver la prueba, el detalle de todas las etapas, tÃ©cnicas, hallazgos y supuestos que se tuvieron en cuenta para solucionar la prueba. Se presentarÃ¡n los cÃ³digos documentados que respaldan el ejercicio analÃ­tico, la presentaciÃ³n de los resultados de la segmentaciÃ³n y el blueprint o arquitectura de la soluciÃ³n.

## 1. IntroducciÃ³n

Bancolombia como entidad regulada y vigilada debe prevenir que sea utilizada para el lavado de activos o para canalizar recursos hacia actividades terroristas. El regulador exige que para aplicar medidas de control mÃ¡s efectivas y simplificar la complejidad de tratar con numerosos clientes, se realice un proceso de segmentaciÃ³n para tener diferencias significativas en sus caracterÃ­sticas. Este proceso se debe realizar periÃ³dicamente y actualmente tiene alta operatividad, requiriendo una capacidad dedicada al 100% de 2 cientÃ­ficos de datos. En promedio se deben mantener 30 modelos con ejecuciones semestrales.

## 2. Objetivo

Esta prueba analÃ­tica tiene como objetivo determinar las capacidades analÃ­ticas para desarrollar e implementar modelos. Debe diseÃ±ar y construir un modelamiento de segmentaciÃ³n partiendo de la informaciÃ³n dada y proponer una soluciÃ³n analÃ­tica E2E cumpliendo prÃ¡cticas de MLOps.
## 4. SoluciÃ³n propuesta

Para abordar el problema de segmentaciÃ³n de clientes, se propone la siguiente soluciÃ³n:

1. **Preprocesamiento de los datos**: Se realizÃ³ un preprocesamiento de los datos para limpiarlos y prepararlos para el anÃ¡lisis y modelamiento.
2. **AnÃ¡lisis exploratorio de los datos**: Se realizÃ³ un anÃ¡lisis exploratorio de los datos para comprender la naturaleza de los datos y detectar posibles patrones.
3. **Feature engineering**: Se realizÃ³ un proceso de ingenierÃ­a de caracterÃ­sticas para crear nuevas variables que puedan ser Ãºtiles para el modelamiento.
4. **Modelamiento de segmentaciÃ³n**: Se aplicaron tÃ©cnicas de clustering para segmentar a los clientes en grupos homogÃ©neos.
5. **EvaluaciÃ³n de los clusters**: Se evaluÃ³ la calidad de los clusters obtenidos.
6. **PresentaciÃ³n de resultados**: Se presentaron los resultados obtenidos en un formato adecuado.
7. **Blueprint de la soluciÃ³n**: Se presentÃ³ un blueprint o arquitectura de la soluciÃ³n propuesta.

## 5. Desarrollo

### 5.1 Preprocesamiento de los datos

En esta etapa se realizÃ³ un preprocesamiento de los datos para limpiarlos y prepararlos para el anÃ¡lisis exploratorio.
Se trataron las varaiables categÃ³ricas teniendo en cuenta la frecuencua de sus niveles, se pasaron a minÃºsculas para homogeneizar la informaciÃ³n.
Se utilizÃ³ el framework de spark para el procesamiento de los datos ya que por su volumen, facilita el procesamiento de los mismos.

### 5.2 AnÃ¡lisis exploratorio de los datos

Se realizÃ³ un anÃ¡lisis exploratorio de los datos para comprender la naturaleza de los datos y detectar posibles patrones.
Se analizaron las variables numÃ©ricas y categÃ³ricas a travÃ©s de un entendimiento de su proporciÃ³n, para las variables numÃ©rcias se utilizÃ³ una descripciÃ³n de los principales estadÃ­sticos. Al ser datos financieros, se observa una distribuciÃ³n asimÃ©trica con sesgo a la derecha, algo normal para este tipo de datos.
Se encontrÃ³ que el conjunto de datos estaba compuesto por dos partes, una parte de caracterÃ­sticas de clientes (un millÃ³n de clientes) y una parte transaccional (cinco millones de transacciones).  Para la parte transaccional, se utilizÃ³ un anÃ¡lisis de las mismas, monto de transacciones promedio, cantidad, etc., se construyÃ³ un perfil transaccional de los clientes.

### 5.3 Feature engineering

Se realizÃ³ un proceso de ingenierÃ­a de caracterÃ­sticas para crear nuevas variables que puedan ser Ãºtiles para el modelamiento. Para las variables categÃ³ricas, se hizo una dummizaciÃ³n teniendo en cuenta que la frecuencia de los niveles fuera superior al 5%, para variables como la ocupaciÃ³n o profesiÃ³n, se realizÃ³ un agrupamiento para obtener menos categorÃ­as, como se muestra a continuaciÃ³n:

```python
OCCUPATION_CATEGORIES = {
    "Professionals": ["profesional independiente", "socio o empleado - socio"],
    "Self-employed": ["independiente", "comerciante", "rentista de capital", "agricultor", "ganadero"],
    "Non-working": ["pensionado", "ama de casa", "estudiante", "desempleado con ingresos", "desempleado sin ingresos"],
    "Others": ["None", "otra"]
}

PROFESSION_CATEGORIES = {
    "STEM": [
        "ingenieria de sistemas", "ingenieria industrial", "ingenieria civil",
        "ingenieria mecanica", "ingeniero electronico", "ingenieria electrica",
        "tecnologia sistemas", "ingeniria quimica", "tecnologia electricidad",
        "tecnologia mecanica", "tecnologia industrial", "ingenieria ambiental",
        "ingenieria administrativa", "biologia", "ingenieria de petroleos",
        "tecnologia agropecuaria", "ingenieria agricola", "ingenieria financiera",
        "tecnologia en construccion", "geologia", "ingenieria forestal",
        "ingenieria de minas", "ingenieria sanitaria", "ingeniero metalurgico",
        "tecnologia en minas", "arquitectura", "agronomia"
    ],

    "Health & Medicine": [
        "medicina", "enfermeria", "odontologia", "quimica farmaceutica",
        "nutricion y dietetica", "auxiliar de enfermeria", "regencia de farmacia",
        "auxiliar de odontologia", "operaciones de equipos medicos",
        "tecnologia en ciencias de la salud", "veterinaria", "bacteriologia"
    ],

    "Business, Law & Administration": [
        "administracion", "contaduria", "derecho", "economia",
        "auxiliar contable", "mercadotecnia", "comercio internacional",
        "secretariado", "tecnologia en administracion", "transportador",
        "carrera militar", "pilotos", "azafata"
    ],

    "Arts, Humanities & Social Sciences": [
        "educacion", "psicologia", "comunicacion social", "diseÃ±o y publicidad",
        "artes", "trabajo social", "profesores de educacion primaria",
        "profesores de educacion preescolar", "sociologia", "filosofia y letras",
        "deportistas entrenadores tecnicos deport", "musicos artistas empresarios y prud espect",
        "escritores periodistas y trabajadores simil", "fotografos y operadores de camara cine y tv",
        "escultores pintores fotografos y art simi", "sacerdote", "religiosa"
    ]
}
```

### 5.4 Modelamiento de segmentaciÃ³n

Para el modelamiento, se utilizÃ³ un modelo base de KMeans con Spark, sirviendo como referencia para otras tÃ©cnicas de segmentaciÃ³n. Inicialmente, se comenzÃ³ la segmentaciÃ³n con 59 variables. Este primer cluster permitiÃ³ identificar aquellas variables con mayor variaciÃ³n. Posteriormente, se aplicÃ³ un modelo de Random Forest para determinar la importancia de las variables en la segmentaciÃ³n.

Considerando estas dos iteraciones: la primera con un KMeans inicial maximizando el indicador de silueta y la segunda con la importancia de las variables del Random Forest, se ejecutÃ³ nuevamente el modelo utilizando KMeans (modelo base) y las K variables mÃ¡s importantes.

## 6. Resultados

En este apartado se explicarÃ¡ el resultado obtenido del anÃ¡lisis de segmentos aplicados a los datos preprocesados mediante las fases anteriores: ETL, EDA y Feature Engineering

### 6.1 Resumen general

Se obtuvo un algoritmo final con las siguientes caracterÃ­sticas:

* **NÃºmero de segmentos:** 7
* **Indicador de silueta:** 0.5536

La distribuciÃ³n de los mismos se muestra a continuaciÃ³n:

| cluster | count  | proportion |
|---------|--------|------------|
| 1       | 21557  | 0.021559  |
| 6       | 161715 | 0.161730  |
| 3       | 175891 | 0.175907  |
| 5       | 203630 | 0.203649  |
| 4       | 91123  | 0.091131  |
| 2       | 177236 | 0.177252  |
| 0       | 168755 | 0.168771  |

![](proporciones_cluster.png)

### 6.2 Segmentos

#### Segmento 1: "Profesionales de la Salud de Alto Ingreso"
- ğŸ¥ Profesionales del sector salud
- ğŸ’° Ingreso mÃ¡s alto (2.475.000)
- ğŸ¦ Usa cuenta de ahorro
- ğŸ‘¥ Predominantemente femenino
- ğŸ’¼ Otras ocupaciones diversas

#### Segmento 2: "Ahorradores de Ingreso Medio-Alto"
- ğŸ’° Ingreso medio-alto (2.000.000)
- ğŸ¦ Usa cuenta de ahorro
- ğŸ‘¥ No hay predominancia de gÃ©nero
- ğŸ’¼ OcupaciÃ³n especÃ­fica no destacada

#### Segmento 3: "Trabajadores Tradicionales"
- ğŸ’° Ingreso medio (1.160.374)
- ğŸ¦ No usa cuenta de ahorro
- ğŸ‘¥ No hay predominancia de gÃ©nero
- ğŸ’¼ OcupaciÃ³n especÃ­fica definida

#### Segmento 4: "Profesionales Urbanos de MedellÃ­n"
- ğŸŒ† Residentes de MedellÃ­n
- ğŸ’° Ingreso medio-alto (1.761.000)
- ğŸ¦ Usa cuenta de ahorro
- ğŸ’¼ Otras ocupaciones diversas

#### Segmento 5: "Hombres Profesionales"
- ğŸ‘¨ Predominantemente masculino
- ğŸ’° Ingreso alto (2.000.000)
- ğŸ¦ Usa cuenta de ahorro
- ğŸ’¼ Otras ocupaciones diversas

#### Segmento 6: "Trabajadores de Ingreso BÃ¡sico"
- ğŸ’° Ingreso mÃ¡s bajo (545.000)
- ğŸ¦ No usa cuenta de ahorro
- ğŸ’¼ Otras ocupaciones diversas
- ğŸ‘¥ No hay predominancia de gÃ©nero

#### Segmento 0: "Hombres Trabajadores de Ingreso Medio-Bajo"
- ğŸ‘¨ Predominantemente masculino
- ğŸ’° Ingreso medio-bajo (936.880)
- ğŸ¦ No usa cuenta de ahorro
- ğŸ’¼ Otras ocupaciones diversas

## 7. Blueprint

A continuaciÃ³n se detalla el blueprint de la soluciÃ³n y se presenta un diagrama de la soluciÃ³n

![](arquitectura.png)

### 1. PreparaciÃ³n del Entorno
- ğŸ› ï¸ ConfiguraciÃ³n del ambiente Spark
- ğŸ“¦ InstalaciÃ³n de dependencias necesarias (matplotlib, numpy, pandas, etc.)
- ğŸ”§ ConfiguraciÃ³n de logs y parÃ¡metros iniciales

### 2. Ingesta y Preprocesamiento de Datos
#### 2.1 Carga de Datos
- ğŸ“¥ Lectura de archivos parquet
- ğŸ” ValidaciÃ³n inicial de datos

#### 2.2 Limpieza de Datos
- ğŸ§¹ EstandarizaciÃ³n de nombres de columnas
- âœ¨ Manejo de valores nulos
- ğŸ”¢ ConversiÃ³n de tipos de datos

#### 2.3 PreparaciÃ³n de Features
- ğŸ“Š IdentificaciÃ³n de variables numÃ©ricas y categÃ³ricas
- ğŸ¯ ValidaciÃ³n de columnas requeridas
- ğŸ”„ TransformaciÃ³n de variables

### 3. Modelado
#### 3.1 Pipeline de TransformaciÃ³n
- âš™ï¸ CreaciÃ³n de Vector Assembler
- ğŸ“ Escalado de caracterÃ­sticas (StandardScaler)
- ğŸ”— ConstrucciÃ³n del pipeline de transformaciÃ³n

#### 3.2 SelecciÃ³n de NÃºmero de Clusters
- ğŸ“ˆ EvaluaciÃ³n de diferentes nÃºmeros de clusters
- ğŸ“Š CÃ¡lculo de mÃ©tricas (Silhouette Score)
- âš–ï¸ AnÃ¡lisis de proporciones de clusters

#### 3.3 Entrenamiento del Modelo
- ğŸ¯ ImplementaciÃ³n de K-means
- ğŸ’¾ Guardado del modelo
- ğŸ”„ GeneraciÃ³n de predicciones

### 4. SelecciÃ³n de CaracterÃ­sticas
#### 4.1 Random Forest para Importancia de Features
- ğŸŒ² Entrenamiento de Random Forest
- ğŸ“Š CÃ¡lculo de importancia de caracterÃ­sticas
- ğŸ¯ SelecciÃ³n de top features

#### 4.2 Reentrenamiento del Modelo
- ğŸ”„ ActualizaciÃ³n con caracterÃ­sticas seleccionadas
- ğŸ“ˆ EvaluaciÃ³n del modelo optimizado
- ğŸ’¾ Guardado del modelo final

### 5. VisualizaciÃ³n y AnÃ¡lisis
#### 5.1 GeneraciÃ³n de GrÃ¡ficos
- ğŸ“Š GrÃ¡ficos de mÃ©tricas de evaluaciÃ³n
- ğŸ“ˆ VisualizaciÃ³n de proporciones de clusters
- ğŸ¨ GrÃ¡fico de coordenadas paralelas

#### 5.2 AnÃ¡lisis de Segmentos
- ğŸ“‹ Resumen estadÃ­stico por cluster
- ğŸ” CaracterizaciÃ³n de segmentos
- ğŸ“ GeneraciÃ³n de perfiles de cliente

### 6. Persistencia y DocumentaciÃ³n
- ğŸ’¾ Guardado de modelos y predicciones
- ğŸ“„ GeneraciÃ³n de reportes
- ğŸ“š DocumentaciÃ³n del proceso

### 7. Control de Calidad
- âœ… ValidaciÃ³n de resultados
- ğŸ” RevisiÃ³n de mÃ©tricas
- ğŸ¯ VerificaciÃ³n de coherencia de segmentos

### 8. Entregables Finales
- ğŸ“Š Visualizaciones interactivas
- ğŸ“‘ Perfiles de segmentos
- ğŸ“ˆ MÃ©tricas de desempeÃ±o
- ğŸ“‹ DocumentaciÃ³n tÃ©cnica
